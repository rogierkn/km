<!DOCTYPE html>
<html lang="en">

<head>
<meta charset="utf-8" />
<link rel="stylesheet" href="https://dokie.li/media/css/lncs.css" />
<title>Summaries for Week 7</title>
</head>

<body>

<h1>Summaries for Week 7</h1>

<h2>Topics</h2>

<h3>Smart, Connected and Open Audio-Visual Content</h3>

<p class="counter">
The Netherlands institute for sound and vision is an organisation that archives audio and video. This is then accessible for individuals but also other organisations. It is busy digitalising old material that is still analogue. A R&D department within is busy researching how to work smarter, connect better and be more open. They try to be more open by giving access to many of its content for free.<br/>
Working smarter is achieved by adding correct metadata to object. This used to be done manually but now other methods are tried. Such methods are image recognition and speech recognition, but also through crowdsourcing.<br/>
Connecting better is achieved by creating links between resources, both internal resources and external resources. For example, linking internal actors to the Wikidata resources, but also to the resources of other similar institutes. For this they use a shared vocabulary.<br/>
Through all this they hope to create new opportunities in creating, curation, consuming and analysing media.
</p>

<h3>Knowledge Maintenance and Evaluation</h3>

<p class="counter">
When a model or system is created it is necessary to evaluate this model to make sure it is correct. There are multiple types of evaluations that can be done. For example, it is possible to evaluate the syntax of a model, the semantic consistency, and the results that a model produces. Another type is principled inspection with the OntoClean methodology. Through this methodology meta-properties are added to classes which are then used to create a backbone hierarchy which can be used to identify inconsistencies. <br/>
Systems can also be evaluated, for example the performance, user experience, or the understandability of knowledge. These can be evaluated through questionnaires, controlled task experiments, but also observations of users using the system.<br/>
What remains important is that evaluations are done on one aspect per evaluation and that they are done carefully.
</p>

<script src="https://rawgit.com/ucds-vu/km2018-portfolio-template/master/scripts.js"></script>

</body>
</html>

